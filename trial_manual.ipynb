{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7dd5cb",
   "metadata": {},
   "source": [
    "validation\n",
    "- number to word\n",
    "- sword-&-shield = sword-and-sorcery "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7677e",
   "metadata": {},
   "source": [
    "open neg+pos reviews, afinn\n",
    "\n",
    "store each review based on sentences\n",
    "\n",
    "sentiment score\n",
    "\n",
    "ver 1 0-10 scale\n",
    "- clean reviews based on afinn, those words not in afinn r removed\n",
    "\n",
    "ver 2 0-1 scale\n",
    "- each review have a score, based on bow, and imdber, calculate the score of each review\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c17c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pip install contractions spacy beautifulsoup4 nltk\n",
    "python -m spacy download en_core_web_sm\n",
    "nltk.download('stopwords')\n",
    "'''\n",
    "import contractions # expands contractions, e.g. don't -> do not\n",
    "from bs4 import BeautifulSoup # removes html tags\n",
    "\n",
    "import spacy # for sentence splitting and tokenization\n",
    "nlp = spacy.load('en_core_web_sm') # load spaCy English model\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # for stopwords\n",
    "english_stopwords = set(stopwords.words('english')) \n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d917774d",
   "metadata": {},
   "source": [
    "# Open imdb.vocab, imdbEr.txt & AFINN-en-165.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718be1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes\n",
      "> vocab_dict : 89527 words\n",
      "> imdbEr : 89527 scores\n",
      "> afinn : 3382 words\n",
      "> combined : 89527 words\n",
      "\n",
      "terrific\n",
      "> AFINN-en-165.txt\n",
      "   > sentiment score : 4\n",
      "> imdb.vocab\n",
      "   > index : 1256\n",
      "   > score : 1.62327578759\n"
     ]
    }
   ],
   "source": [
    "def imdbvocab_dict(filepath):\n",
    "    ''' \n",
    "    function \n",
    "    > open imdb.vocab as dict with word:index \n",
    "    \n",
    "    e.g. {'abandon': 0, 'abandoned': 1, ...}\n",
    "    '''\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        return {line.strip(): idx for idx, line in enumerate(f)} # loop through file & remove empty lines\n",
    "    \n",
    "vocab_dict = imdbvocab_dict('dataset/imdb.vocab') # 89527 words\n",
    "    \n",
    "def imdbEr_list(filepath): \n",
    "    '''\n",
    "    function \n",
    "    > open imdbEr.txt as list of float\n",
    "    \n",
    "    e.g. [0.0, -0.47, ...]\n",
    "    '''\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        return [float(line.strip()) for line in f] # loop through file & remove empty lines\n",
    "    \n",
    "imdbEr = imdbEr_list('dataset/imdbEr.txt') # 89527 scores\n",
    "\n",
    "def afinn_dict(filepath): \n",
    "    '''\n",
    "    function \n",
    "    > open AFINN-en-165.txt as dict with word:score\n",
    "    \n",
    "    e.g. {'abandon': -2, 'abandoned': -2, ...}\n",
    "    '''\n",
    "    with open(filepath, encoding='utf-8') as f:\n",
    "        return {line.split('\\t')[0]: int(line.split('\\t')[1]) for line in f} # loop through file & split by tab\n",
    "    \n",
    "afinn = afinn_dict('dataset/AFINN-en-165.txt') # 3382 words\n",
    "\n",
    "# combine index & score from vocab in a dict\n",
    "combined = {word: (idx, imdbEr[idx]) for word, idx in vocab_dict.items()} # 89527 words\n",
    "\n",
    "print('shapes')\n",
    "print(f'> vocab_dict : {len(vocab_dict)} words')\n",
    "print(f'> imdbEr : {len(imdbEr)} scores')\n",
    "print(f'> afinn : {len(afinn)} words')\n",
    "print(f'> combined : {len(combined)} words')\n",
    "\n",
    "def wordinfo (word):\n",
    "    '''\n",
    "    function\n",
    "    > print word info from afinn & imdb.vocab\n",
    "    \n",
    "    variable\n",
    "    > word : str, word to search\n",
    "    \n",
    "    e.g. wordinfo('terrific')\n",
    "    '''\n",
    "    print(f'\\n{word}')\n",
    "    print('> AFINN-en-165.txt')\n",
    "    print(f'   > sentiment score : {afinn.get(word)}')\n",
    "    print('> imdb.vocab')\n",
    "    print(f'   > index : {combined.get(word)[0]}')\n",
    "    print(f'   > score : {combined.get(word)[1]}')\n",
    "    \n",
    "wordinfo('terrific') # change word to search index & score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff77e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['story of a man who has unnatural feelings for a pig.', 'starts out with a opening scene that is a terrific example of absurd comedy.', 'a formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it is singers.', 'unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting.', 'even those from the era should be turned off.', 'the cryptic dialogue would make shakespeare seem easy to a third grader.', 'on a technical level it is better than you might think with some good cinematography by future great vilmos zsigmond.', 'future stars sally kirkland and frederic forrest can be seen briefly.']\n"
     ]
    }
   ],
   "source": [
    "def opentextfile(filepath):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    with open(filepath, 'r', encoding='utf-8') as f: \n",
    "        text = f.read()\n",
    "\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text() # remove HTML tags\n",
    "    text = contractions.fix(text).lower() # expand contractions\n",
    "    doc = nlp(text) # split sentences and tokenize\n",
    "    fullsentences = [] # keep full sentences for sia, e.g. ['sentence1', 'sentence2', ...]\n",
    "    sentences = [] # keep tokenized sentences for afinn & vocab, e.g. [['token1', 'token2', ...], [...], ...]\n",
    "    for sent in doc.sents:\n",
    "        fullsentences.append(sent.text) \n",
    "        token_list = [] # store words in a sentence e.g. [['word1', 'word2', ...], [], [], ...]\n",
    "        for token in sent:\n",
    "            if not token.is_space: \n",
    "                token_list.append(token.text)\n",
    "        sentences.append(token_list)\n",
    "\n",
    "    return sentences, fullsentences\n",
    "\n",
    "filepath = 'dataset/train/neg/0_3.txt'  \n",
    "sentences, fullsentences = opentextfile(filepath)\n",
    "print(fullsentences)\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc488a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(sentences, scoretype): # sentiment score of each word and sentence\n",
    "    '''\n",
    "    sentences: list of tokenized sentences, e.g. [['token1', 'token2', ...], [...], ...]\n",
    "    scoretype: afinn or combined \n",
    "    return: list of sentence scores, list of word scores for each sentence\n",
    "    \n",
    "    e.g. sentencescore_list = [3, -1, 0, ...]\n",
    "            wordscores_list = [[('word1', 2), ('word2', 1)], [('word3', -1)], [], ...]\n",
    "            \n",
    "            \n",
    "    '''\n",
    "    sentencescore_list = []\n",
    "    wordscores_list = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        wordscoreS = []\n",
    "        score = 0\n",
    "        for word in sentence:\n",
    "            if scoretype is afinn:\n",
    "                if word in scoretype:  \n",
    "                    wordscore = scoretype[word]\n",
    "                    score += wordscore\n",
    "                    wordscoreS.append((word, wordscore))\n",
    "            if scoretype is combined:\n",
    "                if word not in english_stopwords:\n",
    "                    if word in scoretype:  \n",
    "                        wordscore = scoretype[word][1]\n",
    "                        score += wordscore\n",
    "                        wordscoreS.append((word, wordscore))\n",
    "        sentencescore_list.append(score)\n",
    "        wordscores_list.append(wordscoreS)\n",
    "\n",
    "    return sentencescore_list, wordscores_list\n",
    "\n",
    "def slidingwindow(sentencescore_list, windowsize=3): # sliding window for most pos/neg segment\n",
    "    maxscore = None\n",
    "    minscore = None\n",
    "    maxidx = minidx = 0\n",
    "\n",
    "    for i in range(len(sentencescore_list) - windowsize + 1):\n",
    "        windowscore = sum(sentencescore_list[i:i + windowsize])\n",
    "\n",
    "        if maxscore is None or windowscore > maxscore:\n",
    "            maxscore = windowscore\n",
    "            maxidx = i\n",
    "\n",
    "        if minscore is None or windowscore < minscore:\n",
    "            minscore = windowscore\n",
    "            minidx = i\n",
    "\n",
    "    return (maxidx, maxscore), (minidx, minscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00de3990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printsentiment(total, sentences, scores, posidx, negidx, poswin, negwin, windowsize):\n",
    "    print(f'total sentiment score : {total}')\n",
    "    print(f'most pos sentence ({scores[posidx]}) : {sentences[posidx]}')\n",
    "    print(f'most neg sentence ({scores[negidx]}) : {sentences[negidx]}')\n",
    "    \n",
    "    print(f'\\nmost pos segment ({poswin[1]}) :')\n",
    "    for i in range(poswin[0], poswin[0] + windowsize):\n",
    "        print(f'  {i+1} : {sentences[i]}')\n",
    "    \n",
    "    print(f'\\nmost neg segment ({negwin[1]}) :')\n",
    "    for i in range(negwin[0], negwin[0] + windowsize):\n",
    "        print(f'  {i+1} : {sentences[i]}')\n",
    "\n",
    "def sentimentscore(filepath, method, windowsize=3):\n",
    "    if method in ['afinn', 'vocab']:\n",
    "        # Tokenized preprocessing\n",
    "        sentences, fullsentences = opentextfile(filepath)\n",
    "        scoretype = afinn if method == 'afinn' else combined\n",
    "        \n",
    "        # Sentence-level scores\n",
    "        scores, _ = sentiment_score(sentences, scoretype)\n",
    "        total = sum(scores)\n",
    "        \n",
    "        # Sentence indices\n",
    "        posidx, negidx = scores.index(max(scores)), scores.index(min(scores))\n",
    "        \n",
    "        # Sliding windows\n",
    "        poswin, negwin = slidingwindow(scores, windowsize)\n",
    "        \n",
    "        printsentiment(total, fullsentences, scores, posidx, negidx, poswin, negwin, windowsize)\n",
    "    \n",
    "    elif method == 'sia':\n",
    "        # Sentence-based preprocessing\n",
    "        sentences, fullsentences = opentextfile(filepath)\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        \n",
    "        # Sentence-level scores\n",
    "        scores = [sia.polarity_scores(s)['compound'] for s in fullsentences]\n",
    "        total = sum(scores)\n",
    "        \n",
    "        # Sentence indices\n",
    "        posidx, negidx = scores.index(max(scores)), scores.index(min(scores))\n",
    "        \n",
    "        # Sliding windows\n",
    "        window_scores = [\n",
    "            (i, sia.polarity_scores(' '.join(fullsentences[i:i+windowsize]))['compound'])\n",
    "            for i in range(len(fullsentences) - windowsize + 1)\n",
    "        ]\n",
    "        poswin = max(window_scores, key=lambda x: x[1])\n",
    "        negwin = min(window_scores, key=lambda x: x[1])\n",
    "        \n",
    "        printsentiment(total, fullsentences, scores, posidx, negidx, poswin, negwin, windowsize)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('method must be \\'afinn\\', \\'vocab\\', or \\'sia\\'')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94c65e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.6760280775194598, -0.6122235945879999, -4.26666250292146, -3.2194334881679003, -2.032291541066, -5.637296477377749, -0.08888936621250002, -1.91384963009] [[('story', 0.202447200898), ('appallingly', -2.22729553652), ('brutal', 0.865420662809), ('callous', 0.420866499319), ('hero', -0.00915072179286), ('vanquishing', 0.215171487084), ('evil', -0.0763100765738), ('king', 0.277583163506), ('worthless', -2.12555582265), ('almost', -0.0449922079508), ('every', 0.087875564798), ('detail', 0.737911709554)], [('acting', -0.443413788335), ('horrible', -2.14571785916), ('leads', 0.311509442892), ('supporting', 0.972938490902), ('roles', 0.692460119113)], [('leering', -0.347224742073), ('gloating', -0.982802552948), ('glee', 0.335634196639), ('director', -0.168637601385), ('shows', 0.721476098916), ('hero', -0.00915072179286), ('smearing', -0.457442739905), ('blood', -0.192841132259), ('around', -0.224191863485), ('absolutely', -0.312484509531), ('disgusting', -1.50710159992), ('redeemed', -0.254387533996), ('justice', 0.575977219481), ('since', 0.0990306654693), ('bad', -1.46371254094), ('people', -0.107444849484), ('fighting', 0.0286417042921)], [('z', -0.385486352486), ('movie', -0.246354038618), ('editing', -0.449971425073), ('abundant', -0.115576932377), ('including', 0.367511877112), ('scene', -0.137473296436), ('character', -0.0022874579886), ('dies', -0.403409177371), ('sword', -0.0563400843005), ('thrust', 0.42470544095), ('obviously', -0.562260059373), ('missed', 0.0613103526873), ('movie', -0.246354038618), ('clearly', -0.237573959454), ('banking', -0.263688679652), ('charms', 0.52961363792), ('female', -0.292753920158), ('leads', 0.311509442892), ('barbi', -1.27165428204), ('benton', 0.885050612173), ('lana', 0.524017682692), ('clarkson', 0.577074947436), ('paraded', -1.19000458208), ('around', -0.224191863485), ('mostly', -0.0549149743161), ('naked', -0.874772194486), ('throughout', 0.3611938749), ('movie', -0.246354038618)], [('something', -0.357922700721), ('male', -0.171637699354), ('pretend', -0.775611080311), ('female', -0.292753920158), ('flesh', -0.247090850424), ('screen', 0.156712695671), ('attract', -0.343987985769)], [('treatment', 0.0564693438796), ('characters', -0.075112449321), ('degrading', -1.35389755688), ('sex', -0.502907011395), ('scenes', -0.108181251359), ('casual', 0.436014676298), ('joyless', -1.42559543966), ('could', -0.487661330813), ('enjoy', 0.486915195129), ('even', -0.555186494099), ('aspect', 0.177048864127), ('cheesy', -0.800981977921), ('movies', -0.100490333027), ('era', 0.81477903756), ('least', -0.753470093697), ('somewhat', 0.238812558186), ('redeemed', -0.254387533996), ('light', 0.347926569496), ('hearted', 0.918699645967), ('tongue', -0.0452338680467), ('cheek', 0.237597017899), ('feel', 0.252744997659), ('sequel', -0.293129105625), ('better', -0.321028572919), ('regard', -0.00154169443015), ('deathstalker', -1.17771330864), ('seems', -0.295460070581), ('take', -0.0378157464505), ('completely', -0.674607347723), ('seriously', -0.841912588483), ('heroic', 0.231166976413), ('fantasy', 0.270842415075)], [('way', 0.0459494710325), ('!', -0.134838837245)], [('avoid', -1.91384963009)]]\n",
      "total sentiment score : -19.446674677943065\n",
      "most pos sentence (-0.08888936621250002) : ['no', 'way', '!']\n",
      "most neg sentence (-5.637296477377749) : ['but', 'the', 'treatment', 'of', 'their', 'characters', 'is', 'so', 'degrading', 'and', 'the', 'sex', 'scenes', 'so', 'casual', 'and', 'joyless', ',', 'that', 'i', 'could', 'not', 'enjoy', 'even', 'this', 'aspect', 'of', 'the', 'movie.most', 'cheesy', 'movies', 'of', 'this', 'era', 'are', 'at', 'least', 'somewhat', 'redeemed', 'by', 'a', 'light', '-', 'hearted', ',', 'tongue', '-', 'in', '-', 'cheek', 'feel', '(', 'the', 'sequel', 'is', 'better', 'in', 'this', 'regard', ')', ',', 'but', 'deathstalker', 'seems', 'to', 'take', 'itself', 'completely', 'seriously', 'as', 'heroic', 'fantasy', '.']\n",
      "\n",
      "most pos segment (-6.5549141750289195) :\n",
      "  1 : ['this', 'sword-&-sorcery', 'story', 'of', 'an', 'appallingly', 'brutal', 'and', 'callous', '\"', 'hero', '\"', 'vanquishing', 'an', 'evil', 'king', 'is', 'worthless', 'in', 'almost', 'every', 'detail', '.']\n",
      "  2 : ['the', 'acting', 'is', 'horrible', 'from', 'the', 'leads', 'to', 'the', 'supporting', 'roles', '.']\n",
      "  3 : ['the', 'leering', ',', 'gloating', 'glee', 'with', 'which', 'the', 'director', 'shows', 'the', 'hero', 'smearing', 'blood', 'around', 'is', 'absolutely', 'disgusting', ';', 'nor', 'is', 'it', 'redeemed', 'by', 'any', 'justice', 'to', 'his', 'because', ',', 'since', 'he', 'is', 'as', 'bad', 'as', 'the', 'people', 'he', 'is', 'fighting', '.']\n",
      "\n",
      "most neg segment (-10.889021506611648) :\n",
      "  4 : ['z', '-', 'movie', 'editing', 'is', 'abundant', ',', 'including', 'a', 'scene', 'where', 'a', 'character', '\"', 'dies', '\"', 'from', 'a', 'sword', 'thrust', 'that', 'very', 'obviously', 'missed', 'completely!the', 'movie', 'is', 'clearly', 'banking', 'on', 'the', 'charms', 'of', 'the', 'female', 'leads', ',', 'barbi', 'benton', 'and', 'lana', 'clarkson', ',', 'who', 'are', 'paraded', 'around', 'mostly', 'naked', 'throughout', 'the', 'movie', '.']\n",
      "  5 : ['as', 'a', '20', '-', 'something', 'male', ',', 'i', 'will', 'not', 'pretend', 'that', 'female', 'flesh', 'on', 'the', 'screen', 'does', 'not', 'attract', 'me', '.']\n",
      "  6 : ['but', 'the', 'treatment', 'of', 'their', 'characters', 'is', 'so', 'degrading', 'and', 'the', 'sex', 'scenes', 'so', 'casual', 'and', 'joyless', ',', 'that', 'i', 'could', 'not', 'enjoy', 'even', 'this', 'aspect', 'of', 'the', 'movie.most', 'cheesy', 'movies', 'of', 'this', 'era', 'are', 'at', 'least', 'somewhat', 'redeemed', 'by', 'a', 'light', '-', 'hearted', ',', 'tongue', '-', 'in', '-', 'cheek', 'feel', '(', 'the', 'sequel', 'is', 'better', 'in', 'this', 'regard', ')', ',', 'but', 'deathstalker', 'seems', 'to', 'take', 'itself', 'completely', 'seriously', 'as', 'heroic', 'fantasy', '.']\n"
     ]
    }
   ],
   "source": [
    "filepath = 'dataset/train/neg/12481_1.txt'\n",
    "sentimentscore(filepath, method='vocab', windowsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "337e7c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.712009554686, 0.47354348986608, 5.82297235104, 3.41169903933, -0.487001620724, 0.9740855025009999, 3.420291153079, 3.763136070869, 1.5894042956210002, -1.3472051616426, 3.2050926006080003, 3.8702851291930003, 0.8368843551160999, 1.38389101887897, 0.9914952919142] [[('absolutely', -0.312484509531), ('loved', 1.40568694008), ('movie', -0.246354038618), ('!', -0.134838837245)], [('plot', -0.663771954468), ('thrilling', 0.778097454912), ('characters', -0.075112449321), ('well', 0.441646380701), ('developed', -0.00731594195792)], [('cinematography', 0.611919591895), ('stunning', 1.4907307838), ('soundtrack', 0.617625920554), ('perfectly', 1.55772515341), ('complemented', 1.65315215274), ('scenes', -0.108181251359)], [('would', -0.383385991768), ('highly', 1.20549070691), ('recommend', 0.67670059007), ('film', 0.147885815777), ('anyone', -0.213229825818), ('looking', -0.290385920301), ('engaging', 0.632461856895), ('emotional', 0.892561550036), ('experience', 0.743600257529)], [('five', -0.336787095882), ('stars', -0.015375687597), ('!', -0.134838837245)], [('storyline', -0.250576764543), ('kept', -0.278144137817), ('edge', 1.00470723744), ('seat', 0.972685367924), ('start', -0.279249277304), ('finish', -0.195336923199)], [('every', 0.087875564798), ('actor', 0.114703181752), ('delivered', 0.181132207056), ('flawless', 2.27227015992), ('performance', 0.850580207358), ('felt', -0.247338936674), ('real', 0.161068768869)], [('dialogue', -0.629176489809), ('witty', 0.849358978282), ('heartfelt', 1.58744372358), ('perfectly', 1.55772515341), ('timed', 0.397784705406)], [('completely', -0.674607347723), ('immersed', 1.37617452062), ('world', 0.567109694741), ('director', -0.168637601385), ('created', 0.489365029368)], [('pacing', -0.0506123105209), ('right', 0.0471209615653), ('never', -0.109458675416), ('dragging', -0.703699013049), ('rushed', -0.530556124222)], [('soundtrack', 0.617625920554), ('elevated', 0.540609352121), ('every', 0.087875564798), ('scene', -0.137473296436), ('enhanced', 0.838116370471), ('emotions', 1.2583386891)], [('visual', 0.489301847848), ('effects', -0.324797411395), ('breathtaking', 1.896580429), ('seamless', 1.80920026374)], [('laughed', -0.330471262723), ('cried', 1.75433785994), ('felt', -0.247338936674), ('everything', 0.0834458174721), ('watching', -0.423089122899)], [('movie', -0.246354038618), ('exceeded', 1.49367723683), ('expectations', 0.00274278483647), ('every', 0.087875564798), ('way', 0.0459494710325)], [('wait', -0.287001667246), ('watch', -0.0673461151798), ('masterpiece', 1.34584307434)]]\n",
      "total sentiment score : 28.620583070335755\n",
      "most pos sentence (5.82297235104) : ['the', 'cinematography', 'was', 'stunning', ',', 'and', 'the', 'soundtrack', 'perfectly', 'complemented', 'the', 'scenes', '.']\n",
      "most neg sentence (-1.3472051616426) : ['the', 'pacing', 'was', 'just', 'right', ',', 'never', 'dragging', 'or', 'rushed', '.']\n",
      "\n",
      "most pos segment (9.708214880236081) :\n",
      "  2 : ['the', 'plot', 'was', 'thrilling', 'and', 'the', 'characters', 'were', 'so', 'well', 'developed', '.']\n",
      "  3 : ['the', 'cinematography', 'was', 'stunning', ',', 'and', 'the', 'soundtrack', 'perfectly', 'complemented', 'the', 'scenes', '.']\n",
      "  4 : ['i', 'would', 'highly', 'recommend', 'this', 'film', 'to', 'anyone', 'looking', 'for', 'an', 'engaging', 'and', 'emotional', 'experience', '.']\n",
      "\n",
      "most neg segment (3.2122706659092697) :\n",
      "  13 : ['i', 'laughed', ',', 'cried', ',', 'and', 'felt', 'everything', 'in', 'between', 'while', 'watching', '.']\n",
      "  14 : ['this', 'movie', 'exceeded', 'all', 'my', 'expectations', 'in', 'every', 'way', '.']\n",
      "  15 : ['i', 'can', 'not', 'wait', 'to', 'watch', 'it', 'again', '-', 'it', 'is', 'a', 'masterpiece', '.']\n"
     ]
    }
   ],
   "source": [
    "filepath = 'test.txt'\n",
    "sentimentscore(filepath, method='vocab', windowsize=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1154920c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
